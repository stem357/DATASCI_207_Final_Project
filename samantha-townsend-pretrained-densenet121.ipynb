{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":21154,"databundleVersionId":1243559,"sourceType":"competition"},{"sourceId":12588220,"sourceType":"datasetVersion","datasetId":7950456}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-27T04:55:49.812529Z","iopub.execute_input":"2025-07-27T04:55:49.812836Z","iopub.status.idle":"2025-07-27T04:55:52.524390Z","shell.execute_reply.started":"2025-07-27T04:55:49.812802Z","shell.execute_reply":"2025-07-27T04:55:52.522560Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Import the libraries\n%reset -f\nfrom __future__ import print_function\n\nimport math\nimport seaborn as sns\nimport numpy as np\nimport numpy.linalg as nla\nimport pandas as pd\nimport re\nimport six\nfrom os.path import join\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras_tuner import HyperParameters\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import SGD\nimport os\nimport glob\nfrom tensorflow.data.experimental import load\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T04:56:13.311535Z","iopub.execute_input":"2025-07-27T04:56:13.312476Z","iopub.status.idle":"2025-07-27T04:56:32.210046Z","shell.execute_reply.started":"2025-07-27T04:56:13.312437Z","shell.execute_reply":"2025-07-27T04:56:32.209064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\n\nstart_time = time.time()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T04:56:32.211616Z","iopub.execute_input":"2025-07-27T04:56:32.212310Z","iopub.status.idle":"2025-07-27T04:56:32.216822Z","shell.execute_reply.started":"2025-07-27T04:56:32.212276Z","shell.execute_reply":"2025-07-27T04:56:32.215882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Function to decode and normalize the images and standardize to RGB\nimage_size = [224,224]\n\ndef decode_image(image_data):\n    \"\"\"Function to decode the image from the .tfrec\"\"\"\n    ## Converts the raw JPEG file bytes into a 3D tensor, channels=3  indicates RGB, create the shape (height, width, 3), the output is a uint tensor with values 0-255\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    \n    ## Resize all images to the image size specified above [512,512], using bilinear method to smooth the images for efficient processing\n    image = tf.image.resize(image, image_size, method = \"bilinear\")\n    \n    ## Converts the uint to float32, then normalizes the inputs by dividing by the number of pixel values 255\n    ## Removed /255 because EfficientNet expects input [0-255] not [0-1]\n    image = tf.cast(image, tf.float32) \n    \n    ## Takes the image size defined above this function and reshapes it to be the image size [height, width, 3]\n    image = tf.reshape(image, [*image_size,3])\n    return image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T04:56:36.895351Z","iopub.execute_input":"2025-07-27T04:56:36.895809Z","iopub.status.idle":"2025-07-27T04:56:36.902741Z","shell.execute_reply.started":"2025-07-27T04:56:36.895779Z","shell.execute_reply":"2025-07-27T04:56:36.901617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_dataset(filenames, labeled=True):\n    \"\"\"Load TFRecord dataset from filenames\"\"\"\n    ## Creates a dataset that reads the files, AUTOTUNE processes them simultneously and TF optimizes the number of readers\n    ## Creates a dataset of the raw binary .tfrec examples\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=tf.data.AUTOTUNE)\n\n    ## dataset.map applies the read_labeled_tfrec function to each example, AUTOTUNE processes them simultneously and TF optimizes the number of readers\n    ## Transforms the raw data to (image_tensor, label_int) pairs\n    if labeled:\n        dataset = dataset.map(read_labeled_tfrec, num_parallel_calls=tf.data.AUTOTUNE)\n    else:\n        dataset = dataset.map(read_unlabeled_tfrec, num_parallel_calls=tf.data.AUTOTUNE)       \n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T04:56:46.099550Z","iopub.execute_input":"2025-07-27T04:56:46.100055Z","iopub.status.idle":"2025-07-27T04:56:46.106734Z","shell.execute_reply.started":"2025-07-27T04:56:46.100026Z","shell.execute_reply":"2025-07-27T04:56:46.105278Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Function to return an image, label pair for the training and validation sets\ndef read_labeled_tfrec(input_example):\n    \"\"\"Read and parse the labeled .tfrec\"\"\"\n    ## Tells Tensorflow how to interpret the binary .tfrec data, \"image\" tells TF to expect binary jppeg bytes, \"class\" tells TF to expect integer labels (the flower labels)\n    labeled_tfrec_format = { \n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"class\": tf.io.FixedLenFeature([], tf.int64)\n    }\n    ## Parses the input_example using the format specified above\n    ## Takes raw binary data (input_example) and uses the labeled_tfrec_format to return a dictionary {image bytes, flower label}\n    input_example = tf.io.parse_single_example(input_example, labeled_tfrec_format)\n    \n    ## Process the image - Takes the JPEG bytes from the example image, and normalizes them to a [512,512,3] tensor using the decode_image function\n    image = decode_image(input_example[\"image\"])\n    \n    ## Process the label - input_example['class'] is the flower class ID\n    label = tf.cast(input_example['class'], tf.int32)\n    return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T04:56:54.543459Z","iopub.execute_input":"2025-07-27T04:56:54.544116Z","iopub.status.idle":"2025-07-27T04:56:54.549838Z","shell.execute_reply.started":"2025-07-27T04:56:54.544088Z","shell.execute_reply":"2025-07-27T04:56:54.548691Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Function to return an image without labels for the test set\ndef read_unlabeled_tfrec(input_example):\n    \"\"\"Read and parse the unlabeled .tfrec\"\"\"\n    unlabeled_tfrec_format = { \n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"id\": tf.io.FixedLenFeature([], tf.string)\n    }    \n    input_example = tf.io.parse_single_example(input_example, unlabeled_tfrec_format)\n    \n    ## Process the image - Takes the JPEG bytes from the example image, and normalizes them to a [512,512,3] tensor using the decode_image function\n    image = decode_image(input_example[\"image\"])\n    \n    ## Process the label - input_example['id'] is the image ID\n    image_id = input_example['id']\n    return image, image_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T04:57:04.007772Z","iopub.execute_input":"2025-07-27T04:57:04.008205Z","iopub.status.idle":"2025-07-27T04:57:04.015181Z","shell.execute_reply.started":"2025-07-27T04:57:04.008173Z","shell.execute_reply":"2025-07-27T04:57:04.014250Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Get filenames for 224x224 images only\nfolder = 'tfrecords-jpeg-224x224'\ntrain_files = tf.io.gfile.glob(f\"/kaggle/input/tpu-getting-started/{folder}/train/*.tfrec\")\nval_files = tf.io.gfile.glob(f\"/kaggle/input/tpu-getting-started/{folder}/val/*.tfrec\")\ntest_files = tf.io.gfile.glob(f\"/kaggle/input/tpu-getting-started/{folder}/test/*.tfrec\")\n\n## Create train, validation and test data set\ntrain_dataset = load_dataset(train_files, labeled=True)\nvalidation_dataset = load_dataset(val_files, labeled=True)\ntest_dataset = load_dataset(test_files, labeled=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T04:57:12.551222Z","iopub.execute_input":"2025-07-27T04:57:12.551656Z","iopub.status.idle":"2025-07-27T04:57:12.880227Z","shell.execute_reply.started":"2025-07-27T04:57:12.551623Z","shell.execute_reply":"2025-07-27T04:57:12.879295Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Shuffling the training and validation sets\n\n## Sets random seed for reproducability\ntf.random.set_seed(42)\n\n## Set shuffle buffer to set how many are shuffled at once\nshuffle_buffer = 500\n\n## Shuffle the training set\ntrain_dataset = train_dataset.shuffle(shuffle_buffer, seed=42, reshuffle_each_iteration=False)\n\n## Shuffle the validation set\nvalidation_dataset = validation_dataset.shuffle(shuffle_buffer, seed=42, reshuffle_each_iteration=False)\n\n## No shuffling of test data as it's not needed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T04:57:23.655080Z","iopub.execute_input":"2025-07-27T04:57:23.655391Z","iopub.status.idle":"2025-07-27T04:57:23.681635Z","shell.execute_reply.started":"2025-07-27T04:57:23.655369Z","shell.execute_reply":"2025-07-27T04:57:23.680809Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Set hyperparameters\n## Sets the batch to 32 as the number of images to be processed at a time durin one forward/backward pass through the model, 32 is a default\n## Larger batches take more memory and are more stable but if they batch is too large the model may generalize poorly\nBATCH_SIZE = 32\n## Tensorflow optimization that automatically determines the most optimal number of parallel processes\nAUTO = tf.data.AUTOTUNE\n## Sets the number of classes to the number of flower categories\nNUM_CLASSES = 104\n\n## Prepare the datasets for training by grouping a batch based on the size set above, and pre-fetches the next batch while the current batch is being processed\ntrain_dataset = train_dataset.batch(BATCH_SIZE).prefetch(AUTO)\nvalidation_dataset = validation_dataset.batch(BATCH_SIZE).prefetch(AUTO)\ntest_dataset = test_dataset.batch(BATCH_SIZE).prefetch(AUTO)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T04:57:34.799887Z","iopub.execute_input":"2025-07-27T04:57:34.800207Z","iopub.status.idle":"2025-07-27T04:57:34.818367Z","shell.execute_reply.started":"2025-07-27T04:57:34.800186Z","shell.execute_reply":"2025-07-27T04:57:34.817343Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Optimizer & Learning Rate\n# ================================\nfrom tensorflow.keras.optimizers.schedules import CosineDecay\nfrom tensorflow.keras.optimizers import Adam\n\n# Hyperparameters\ninitial_lr = 1e-3\nBATCH_SIZE = 32\nNUM_TRAIN_IMAGES = 12752  # Update this if different\n\n# Compute steps per epoch\nsteps_per_epoch = NUM_TRAIN_IMAGES // BATCH_SIZE\n\n# Cosine Decay Schedule over 80 epochs\nlr_schedule = CosineDecay(initial_lr, decay_steps=steps_per_epoch * 80)\n\n# Optimizer\noptimizer = Adam(learning_rate=lr_schedule)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Define Updated DenseNet121 Model\n# ================================\ndef create_model():\n    base_model = tf.keras.applications.DenseNet121(\n        include_top=False,\n        weights=\"/kaggle/input/pretrained-weights/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n        input_shape=(224, 224, 3),\n        pooling='avg'\n    )\n    base_model.trainable = False\n\n    model = tf.keras.Sequential([\n        tf.keras.layers.RandomFlip(\"horizontal\"),\n        tf.keras.layers.RandomRotation(0.2),\n        tf.keras.layers.RandomZoom(0.2),\n        tf.keras.layers.RandomContrast(0.1),\n        base_model,\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n    ])\n    return model, base_model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Custom Callback for Partial Unfreezing\n# ================================\nclass UnfreezeCallback(tf.keras.callbacks.Callback):\n    def __init__(self, base_model, unfreeze_at=5):\n        super().__init__()\n        self.base_model = base_model\n        self.unfreeze_at = unfreeze_at\n\n    def on_epoch_begin(self, epoch, logs=None):\n        if epoch == self.unfreeze_at:\n            print(f\"\\nUnfreezing top 100 layers of DenseNet121 at epoch {epoch}\")\n            self.base_model.trainable = True\n            for layer in self.base_model.layers[:-100]:\n                layer.trainable = False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Model Compilation & Training\n# ================================\nmodel, base_model = create_model()\n\nmodel.compile(\n    optimizer=optimizer,\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # removed label_smoothing\n    metrics=['accuracy']\n)\n\n\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss', restore_best_weights=True),\n    UnfreezeCallback(base_model, unfreeze_at=5),\n    tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True),\n]\n\nhistory = model.fit(\n    train_dataset,\n    validation_data=validation_dataset,\n    epochs=80,\n    callbacks=callbacks\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Plot Accuracy and Loss\n# ================================\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.grid(True)\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.grid(True)\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Save the Model\n# ================================\nval_loss, val_acc = model.evaluate(validation_dataset)\nprint(f\"Validation Accuracy: {val_acc:.4f}\")\nprint(f\"Validation Loss: {val_loss:.4f}\")\n\nmodel.save(\"Samantha_Townsend_flower_densenet121_final.h5\")\nprint(\"Model saved as Samantha_Townsend_flower_densenet121_final.h5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Evaluate and Predict\n# ================================\nval_loss, val_acc = model.evaluate(validation_dataset)\nprint(f\"Validation Accuracy: {val_acc:.4f}\")\nprint(f\"Validation Loss: {val_loss:.4f}\")\n\n# Predict test labels\npredictions = model.predict(test_dataset, verbose=1)\npredicted_labels = tf.argmax(predictions, axis=1).numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Evaluate and Predict\n# ================================\npredictions = model.predict(test_dataset, verbose=1)\npredicted_labels = tf.argmax(predictions, axis=1).numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Prepare Submission\n# ================================\n\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\n\n# === Load your trained model ===\nmodel = tf.keras.models.load_model(\"Samantha_Townsend_flower_densenet121_final.h5\")\nprint(\"Model loaded successfully.\")\n\n# === Load sample_submission.csv to get correct ID order ===\nsubmission_template = pd.read_csv(\"/kaggle/input/tpu-getting-started/sample_submission.csv\")\ntest_ids = submission_template[\"id\"].tolist()\n\n# === Define test TFRecord loading function ===\ndef parse_image(example):\n    feature_description = {\n        \"id\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(example, feature_description)\n    image = tf.io.decode_jpeg(example[\"image\"], channels=3)\n    image = tf.image.resize(image, [224, 224])\n    image = tf.cast(image, tf.float32) / 255.0\n    return example[\"id\"], image\n\n# === Load test dataset (unlabeled) ===\ntest_files = tf.io.gfile.glob(\"/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/*.tfrec\")\nraw_test_ds = tf.data.TFRecordDataset(test_files, num_parallel_reads=tf.data.AUTOTUNE)\ntest_ds = raw_test_ds.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n\n# === Store images in a dict keyed by ID for matching ===\ntest_image_map = {}\nfor img_id, img in test_ds:\n    test_image_map[img_id.numpy().decode()] = img.numpy()\n\n# === Create batch input in the order of submission template ===\nordered_images = np.stack([test_image_map[i] for i in test_ids])\nprint(f\"Loaded {len(ordered_images)} test images in order.\")\n\n# === Make predictions ===\npred_probs = model.predict(ordered_images, batch_size=32, verbose=1)\npred_labels = np.argmax(pred_probs, axis=1)\n\n# === Create final submission ===\nsubmission_df = pd.DataFrame({\n    \"id\": test_ids,\n    \"label\": pred_labels\n})\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"submission.csv saved successfully!\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}